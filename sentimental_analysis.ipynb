{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8BAleQSwt9p",
        "outputId": "e617d67a-160f-419b-dc7c-7f3a6da27b59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n"
          ]
        }
      ],
      "source": [
        "pip install torch transformers datasets scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "\n",
        "from datasets import load_dataset\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "cmTNuC-vw2PV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrksiIz8w2kI",
        "outputId": "6f62488a-cfec-4a5c-8d9d-bdd568d453e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD IMDb DATASET\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "train_texts = dataset[\"train\"][\"text\"]\n",
        "train_labels = dataset[\"train\"][\"label\"]\n",
        "\n",
        "test_texts = dataset[\"test\"][\"text\"]\n",
        "test_labels = dataset[\"test\"][\"label\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345,
          "referenced_widgets": [
            "5f892b949f884557a4ad488f8c000c79",
            "372a7790d4c34bcb82e979a78eea045a",
            "86b710d1717448d69fea3d5cc9d22ab5",
            "734585973b07416b8f2ad2629f79d6b2",
            "99342d72b14b4e938aa1f0c590223da8",
            "d42fc0a3a1eb4694b040e84ab925fae1",
            "ff036283b07848d1bbc91ee6fef24b4d",
            "bec8c3b1d61a4d85a07ceb779d875443",
            "8e2d21a954d64b82b58f75a1eb4f0649",
            "58534b03ec094c80bd72d8fd302c06d4",
            "da8337e868da46c8b6eeac6ac13e1bdd",
            "e024e1fa298c43898bc8571dbc4bef8f",
            "8d8baea200144c4ea2338cc52dec3b88",
            "8c8b5e561f9a44c1b82b74e4620ac94b",
            "0359b1eb46d141d392f69c4907d03500",
            "e900bd17e76c4c189c82b352cf7ce3cf",
            "8e90c137faf74961af139459e4efbc68",
            "efa1915ac2a54301a675f3528abd73dc",
            "6391008202524b4c96e1bfa62ad0ef44",
            "5ddb6431b4ad455b9050b86aba69488e",
            "8c9407b453644f6c878f4edabcf935e8",
            "d0dcd7dce51f469fa3a55e56fb333eb1",
            "5b025978b11b44f29a60a564a91b7085",
            "231559987451467d93f413f38e49b6e3",
            "0d8be3b5b7c142ab80448dae9399327e",
            "adf41511165d416294290a58aaef932e",
            "69872e40dbd14607baf0fb05fce7a3e3",
            "f7d6546cc88d4f6fa5ff16eff9ffb380",
            "1b93761d12a84d8aa1a20a31e7078bb1",
            "37bcba34ea994370a5d62cecbdd3c2e4",
            "72902642102145248ac3254fac5ed04c",
            "97675f36e2cc4c2ca1416d70050f72f1",
            "fe76c8de316948cebafb0f938ed5c0f4",
            "aede5ade66304af8b20903bc92279ced",
            "ab52c319807f4f61aadc5590b336c7be",
            "febe020b581e409ba706cf7a9b22da5b",
            "ba54376420ac4c8e9d51da73107beb19",
            "7e220d03ec084fd2940c840980cfb3cb",
            "83f16fe1957540c1b55b08e410ed0725",
            "a0f803af66d3443c9b84f4a27db21e75",
            "bb97fe1c6e184af78df302f89e8b47df",
            "5ce9a78ef1fd4111b1e216d310bb1dc8",
            "2d55d1da19604c6ab6cb4efaf5ed884b",
            "c7a4af9d8e6d46a7a56e663aa3313095",
            "e5499354390246f19c7420a9e57b133a",
            "233006392ff74245a77d3b0d1cdb2269",
            "6574613e7dd045b5be25af3b90e8284f",
            "7021d769d9274bf3aefeb98f74ba1c94",
            "14eb009628774fa0a910760f79e62f7f",
            "bf6e8109bb504a67a4e5832fc2af4f85",
            "6dd8e56142e5447e94bf29103fd4addc",
            "195caa42719e4ef8a106101b0c32567e",
            "fc59cdfdaac7467eb7b0123d63ad68f1",
            "113bbe09c6504721bcf7a78ecd495401",
            "57e4a8ba75494f52b2d300dc8d0b33a8",
            "62dfb5c472504d10ab2fd41e6531b09a",
            "65db969006624ec6b27897b49bc1cd10",
            "8ed09f31d33d424ba361802d1ea80b8a",
            "dc5a8e7adfa94bfb8adb254f95095b3f",
            "c9f0064bbde749919d1f1ca085048702",
            "48fa2ef75dbd4957a88ef4812fb43887",
            "63501a02e5d145ac95f74797b6cae12b",
            "92fc817a11174a92a11a368b4cb711a4",
            "f0a2acf6acd745b6855f6ffdce2c3330",
            "fdf3d041a1a148d1817bb1244d8a8e8e",
            "ccddaf2aec254383bdd39810f5e45def",
            "6dd1c828e7174cc088ea653a8a51f3a0",
            "b1ee2fe00d0c4887bf093376145db39f",
            "41c2c5b1ce7043e0bdd5096edcb10041",
            "12c56aadbc694e5e9a34d674302db595",
            "711fdfa391ee409b90f319a660167a80",
            "46ce06cb3421401b8e80ee0eeddcf0df",
            "86108448aedc42e987977329f6383266",
            "d06911d763484f259d019841c1a9bc18",
            "9eb9671805ca4085b12c1a3691dd38a7",
            "5ce3335d4ea44c09b0fa252dd4fe7a08",
            "ee889b75c6704f4691f85abfcc05b2b2"
          ]
        },
        "id": "0F7082Ypw23R",
        "outputId": "516298cd-f7d2-4861-dca2-dcf9925f7049"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f892b949f884557a4ad488f8c000c79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e024e1fa298c43898bc8571dbc4bef8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b025978b11b44f29a60a564a91b7085"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/unsupervised-00000-of-00001.p(â€¦):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aede5ade66304af8b20903bc92279ced"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5499354390246f19c7420a9e57b133a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62dfb5c472504d10ab2fd41e6531b09a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6dd1c828e7174cc088ea653a8a51f3a0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lstm\n",
        "# Text Preprocessing\n",
        "def tokenize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
        "    return text.split()"
      ],
      "metadata": {
        "id": "hNJ_cE-XzVFW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB = 20000\n",
        "MAX_LEN = 300\n",
        "\n",
        "PAD = \"<pad>\"\n",
        "UNK = \"<unk>\"\n",
        "\n",
        "counter = Counter()\n",
        "for text in train_texts:\n",
        "    counter.update(tokenize(text))\n",
        "\n",
        "vocab = {PAD: 0, UNK: 1}\n",
        "for word, _ in counter.most_common(MAX_VOCAB - 2):\n",
        "    vocab[word] = len(vocab)"
      ],
      "metadata": {
        "id": "MSm0-eTtzVXQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding\n",
        "def encode(text):\n",
        "    tokens = tokenize(text)\n",
        "    ids = [vocab.get(t, vocab[UNK]) for t in tokens][:MAX_LEN]\n",
        "    return ids + [0] * (MAX_LEN - len(ids))"
      ],
      "metadata": {
        "id": "mCI6NrM4zVgL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset\n",
        "class LSTMDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            torch.tensor(encode(self.texts[idx]), dtype=torch.long),\n",
        "            torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        )"
      ],
      "metadata": {
        "id": "_zu1LuGHzVm9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lstm model\n",
        "class SentimentLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, 128, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(128, 256, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        _, (h, _) = self.lstm(x)\n",
        "        return self.fc(self.dropout(h[-1]))"
      ],
      "metadata": {
        "id": "oRI4mazwzVs_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train and evaluate\n",
        "train_loader = DataLoader(\n",
        "    LSTMDataset(train_texts, train_labels),\n",
        "    batch_size=64, shuffle=True\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    LSTMDataset(test_texts, test_labels),\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "lstm_model = SentimentLSTM(len(vocab)).to(device)\n",
        "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "plGghd4czV0G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lstm():\n",
        "    lstm_model.train()\n",
        "    for epoch in range(5):\n",
        "        loss_sum = 0\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(lstm_model(x), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_sum += loss.item()\n",
        "        print(f\"LSTM Epoch {epoch+1} Loss: {loss_sum/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "y4uV1qV0zt07"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, loader):\n",
        "    model.eval()\n",
        "    preds, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            preds.extend(model(x).argmax(1).cpu().numpy())\n",
        "            labels.extend(y.numpy())\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
        "    return acc, p, r, f"
      ],
      "metadata": {
        "id": "Q8yfu2Nzzt9B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lstm()\n",
        "lstm_results = eval_model(lstm_model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brKMHNtvzuAa",
        "outputId": "a1e5764f-965e-41f1-9f37-f3b196e11a94"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Epoch 1 Loss: 0.6931\n",
            "LSTM Epoch 2 Loss: 0.6870\n",
            "LSTM Epoch 3 Loss: 0.6694\n",
            "LSTM Epoch 4 Loss: 0.6527\n",
            "LSTM Epoch 5 Loss: 0.6221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AWD-LSTM (ULMFiT)\n",
        "from fastai.text.all import *\n",
        "\n",
        "# Load IMDb dataset\n",
        "path = untar_data(URLs.IMDB)\n",
        "\n",
        "dls = TextDataLoaders.from_folder(\n",
        "    path, train='train', valid='test', bs=64\n",
        ")\n",
        "\n",
        "# Create learner\n",
        "awd_learner = text_classifier_learner(\n",
        "    dls, AWD_LSTM, metrics=accuracy\n",
        ")\n",
        "\n",
        "# Fine-tune\n",
        "awd_learner.fit_one_cycle(1, 2e-2)\n",
        "awd_learner.unfreeze()\n",
        "awd_learner.fit_one_cycle(2, slice(1e-4, 1e-3))\n",
        "\n",
        "# Get accuracy (float)\n",
        "awd_acc = awd_learner.validate()[1]\n",
        "print(\"AWD-LSTM Accuracy:\", awd_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "Xed_UslMzuEo",
        "outputId": "51158d26-9768-4c82-c9f4-6627703f309e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.432329</td>\n",
              "      <td>0.372677</td>\n",
              "      <td>0.835760</td>\n",
              "      <td>03:23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.291515</td>\n",
              "      <td>0.237536</td>\n",
              "      <td>0.901880</td>\n",
              "      <td>07:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.248820</td>\n",
              "      <td>0.210534</td>\n",
              "      <td>0.918040</td>\n",
              "      <td>07:27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AWD-LSTM Accuracy: 0.9180399775505066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds, labels = awd_learner.get_preds()\n",
        "pred_labels = preds.argmax(dim=1)\n",
        "awd_acc = accuracy_score(labels, pred_labels)\n",
        "awd_prec, awd_rec, awd_f1, _ = precision_recall_fscore_support(labels, pred_labels, average='binary')\n",
        "print(f\"AWD-LSTM Results: Accuracy={awd_acc:.4f}, Precision={awd_prec:.4f}, Recall={awd_rec:.4f}, F1={awd_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "xUzOOuzYTIDl",
        "outputId": "768c92c0-315e-434e-8211-6c07c66b049d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AWD-LSTM Results: Accuracy=0.9180, Precision=0.9206, Recall=0.9150, F1=0.9178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT TRANSFORMER\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import AdamW"
      ],
      "metadata": {
        "id": "8O3p5Qbe0MMg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def bert_encode(texts):\n",
        "    return tokenizer(\n",
        "        texts, padding=True, truncation=True,\n",
        "        max_length=256, return_tensors=\"pt\"\n",
        "    )"
      ],
      "metadata": {
        "id": "95DcX04M0MPv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "46a19e5ed88a4d1b8f404421376360bd",
            "506f9ca65eab4430837d8627ca605a6c",
            "c7eb6d0ec40547fa9fb355e6fa7e5ca8",
            "1f3f94c45ca24f9bbad5a7fe8e34e468",
            "514fbcb53c3e427ea6a9ac1b581701e5",
            "35009fa5a59943259b0ad558017319d6",
            "56e14a77b078418c9494844ae8bbcc11",
            "13770aa476734b0ea0c98f730eecaaf4",
            "45ef404b26a64f59883992af3cd6fbe5",
            "62e4f49eafba4809b8d7e56816f9c961",
            "c6a22c771f02464a92f436ba5b084628",
            "b6c46b1a24d54aa085f3c6cc55a4d357",
            "7da79efce1924c7180d45c2fc58580e1",
            "800361bc53b1490dad585bcd153fbee6",
            "e9f4f0d5794d450292fe2fa0a40f1c93",
            "dd86be9461a149a1b4160370c88f702a",
            "d753c794ab6348d39f62d72a1dc78c48",
            "eb90902f656b4f85ad50b63f2288550b",
            "013c3f814c004ee0b7a0a53250b79853",
            "91c57ef63ae14666b8c3087d4e2afb8e",
            "1efa2917b24d4215ab890e353c7139ec",
            "b61696eea8b848f0ba38e2f9893a2afa",
            "9e1d96c63261494cbeca946f8d6f87bf",
            "a1c847bfec314532b3dd281762db91a8",
            "2761f533aded45a286c7b13cfe0f18a6",
            "24af975be09e466982dabd3fd97ebb60",
            "2e2ba0e76d49466b9a22be530f552c22",
            "6e897579142040ecb2a6eb8ee3557266",
            "fefafc018d8b476f95e4ccdd1206ae99",
            "f74282f814164a34818707e325e91c58",
            "1ed1bedd01654ffbab8daaa69a8cb399",
            "decbf8285b4a40a188bcee9d2bf24fd0",
            "703fef7ce0ff4408b55d5b8445ed499a",
            "d328a31ba5ba4aeb87970b8d6121e594",
            "08120064908b4e969c4269d9c60e20a3",
            "14533d4f5d5e4eef86466df0cc80f456",
            "bd43776e1bed49e79c44bdcb18e05ba0",
            "91c601cbcb054cbf8052602357b780a3",
            "e18b7fe07e724fa8837dc5e44c12986a",
            "efad7b7b511a4bffbb0344a55a9388ef",
            "84ce510185b5403e88b4dae4f19ce50c",
            "d60c2ac6011240e682765833c671b074",
            "6723f111e9f141b4b9a4930f51b4ee4d",
            "f172df64f674451fbff7173a49af4f80"
          ]
        },
        "outputId": "0d0eef5f-6f23-4958-cd09-93ff76d9bd81"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46a19e5ed88a4d1b8f404421376360bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6c46b1a24d54aa085f3c6cc55a4d357"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e1d96c63261494cbeca946f8d6f87bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d328a31ba5ba4aeb87970b8d6121e594"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset\n",
        "class BERTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=256):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "SQQPBZ7b0MU-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.optim import AdamW\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "train_dataset = BERTDataset(train_texts, train_labels, tokenizer)\n",
        "test_dataset = BERTDataset(test_texts, test_labels, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)"
      ],
      "metadata": {
        "id": "Z5IpeZl10a8e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bert(model, loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)"
      ],
      "metadata": {
        "id": "H2QvHXvx0a_-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=2\n",
        ").to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "Ct1K-PM10bDq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "dd68b1d6588d4a30a6a488d9dc73515a",
            "67d24952454641e7b24664ff71063c91",
            "8a148be25b3c4e918fe2f92f74823122",
            "a108aedf6e01497da6c0928d24387603",
            "a9255547195841fdbf73d0253db6f9fe",
            "fbaee38be1d54b27be01dc2338c4c997",
            "310d034e5f3d44759cb18d4886e4e6ea",
            "0eade6562b904541a513bf2dd7dc2111",
            "9e1d8c33095a4f21adc231fa894e2ede",
            "9f25054ca72c4ffeab59980578d5df98",
            "9722d0f710bd4254b0f690e01d09bff8"
          ]
        },
        "outputId": "8abb724a-59b6-441d-9fc5-50c82c87ff4f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd68b1d6588d4a30a6a488d9dc73515a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    loss = train_bert(model, train_loader, optimizer)\n",
        "    print(f\"BERT Epoch {epoch+1}/{EPOCHS} | Loss: {loss:.4f}\")"
      ],
      "metadata": {
        "id": "VgNPtWdK2CB6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87f2cc5-6a38-435b-d581-201bafbc1423"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Epoch 1/3 | Loss: 0.2679\n",
            "BERT Epoch 2/3 | Loss: 0.1411\n",
            "BERT Epoch 3/3 | Loss: 0.0719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_bert(model, loader):\n",
        "    model.eval()\n",
        "    preds, labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            labels.extend(batch[\"labels\"].numpy())\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            preds.extend(outputs.logits.argmax(1).cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
        "    return acc, p, r, f"
      ],
      "metadata": {
        "id": "RWoalY6L2F3F"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results = evaluate_bert(model, test_loader)\n",
        "print(\"BERT Results:\", bert_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naXCeYxtPc0f",
        "outputId": "58fae486-b0a0-45b9-ee2b-c36f1ea75e48"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Results: (0.9182, 0.9229026777768788, 0.91264, 0.9177426491291582)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFINAL COMPARISON\\n\")\n",
        "\n",
        "print(\"Custom LSTM  :\", lstm_results)\n",
        "print(\"AWD-LSTM Acc :\", awd_acc)\n",
        "print(\"BERT         :\", bert_results)"
      ],
      "metadata": {
        "id": "QkIuu9FO0bHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7664c49-ff5a-472b-b205-816b32f0f6bc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FINAL COMPARISON\n",
            "\n",
            "Custom LSTM  : (0.5098, 0.5542755870624723, 0.10008, 0.16954665582435455)\n",
            "AWD-LSTM Acc : 0.9180399775505066\n",
            "BERT         : (0.9182, 0.9229026777768788, 0.91264, 0.9177426491291582)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFINAL COMPARISON TABLE\\n\")\n",
        "print(f\"{'Model':<15} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1':<10}\")\n",
        "print(f\"{'Custom LSTM':<15} {lstm_results[0]:<10.4f} {lstm_results[1]:<10.4f} {lstm_results[2]:<10.4f} {lstm_results[3]:<10.4f}\")\n",
        "print(f\"{'AWD-LSTM':<15} {awd_acc:<10.4f} {awd_prec:<10.4f} {awd_rec:<10.4f} {awd_f1:<10.4f}\")\n",
        "print(f\"{'BERT':<15} {bert_results[0]:<10.4f} {bert_results[1]:<10.4f} {bert_results[2]:<10.4f} {bert_results[3]:<10.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSu-En5_PbkS",
        "outputId": "7761e9c8-3d6d-44e9-c4f3-1254e9aba6c3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FINAL COMPARISON TABLE\n",
            "\n",
            "Model           Accuracy   Precision  Recall     F1        \n",
            "Custom LSTM     0.5098     0.5543     0.1001     0.1695    \n",
            "AWD-LSTM        0.9180     0.9206     0.9150     0.9178    \n",
            "BERT            0.9182     0.9229     0.9126     0.9177    \n"
          ]
        }
      ]
    }
  ]
}