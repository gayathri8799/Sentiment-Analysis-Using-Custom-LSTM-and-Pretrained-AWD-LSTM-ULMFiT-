# IMPORTS
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import numpy as np
import random
import re
import time
from collections import Counter
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

# FastAI for AWD-LSTM
from fastai.text.all import *

# HuggingFace Transformers for BERT
from transformers import BertTokenizer, BertForSequenceClassification
from torch.optim import AdamW
from datasets import load_dataset

# REPRODUCIBILITY
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# LOAD IMDb DATASET
dataset = load_dataset("imdb")
train_texts = dataset["train"]["text"]
train_labels = dataset["train"]["label"]
test_texts  = dataset["test"]["text"]
test_labels = dataset["test"]["label"]

# PART 1: CUSTOM LSTM

# TOKENIZATION
def tokenize(text):
    text = text.lower()
    text = re.sub(r"[^a-z0-9\s]", "", text)
    return text.split()

# VOCAB
MAX_VOCAB = 20000
MAX_LEN = 300
PAD = "<pad>"
UNK = "<unk>"

counter = Counter()
for text in train_texts:
    counter.update(tokenize(text))

vocab = {PAD:0, UNK:1}
for word, _ in counter.most_common(MAX_VOCAB-2):
    vocab[word] = len(vocab)

def encode(text):
    tokens = tokenize(text)
    ids = [vocab.get(t, vocab[UNK]) for t in tokens][:MAX_LEN]
    return ids + [0]*(MAX_LEN - len(ids))

# DATASET CLASS
class LSTMDataset(Dataset):
    def __init__(self, texts, labels):
        self.texts = texts
        self.labels = labels
    def __len__(self):
        return len(self.labels)
    def __getitem__(self, idx):
        return torch.tensor(encode(self.texts[idx]), dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)

# MODEL
class SentimentLSTM(nn.Module):
    def __init__(self, vocab_size):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, 128, padding_idx=0)
        self.lstm = nn.LSTM(128, 256, batch_first=True)
        self.dropout = nn.Dropout(0.3)
        self.fc = nn.Linear(256, 2)
    def forward(self, x):
        x = self.embedding(x)
        _, (h, _) = self.lstm(x)
        return self.fc(self.dropout(h[-1]))

# TRAIN & EVAL
train_loader_lstm = DataLoader(LSTMDataset(train_texts, train_labels), batch_size=64, shuffle=True)
test_loader_lstm  = DataLoader(LSTMDataset(test_texts, test_labels), batch_size=64)

lstm_model = SentimentLSTM(len(vocab)).to(device)
optimizer_lstm = torch.optim.Adam(lstm_model.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()

def train_lstm():
    lstm_model.train()
    for epoch in range(5):
        loss_sum = 0
        for x, y in train_loader_lstm:
            x, y = x.to(device), y.to(device)
            optimizer_lstm.zero_grad()
            loss = criterion(lstm_model(x), y)
            loss.backward()
            optimizer_lstm.step()
            loss_sum += loss.item()
        print(f"LSTM Epoch {epoch+1} | Loss: {loss_sum/len(train_loader_lstm):.4f}")

def eval_model(model, loader):
    model.eval()
    preds, labels = [], []
    with torch.no_grad():
        for x, y in loader:
            x = x.to(device)
            preds.extend(model(x).argmax(1).cpu().numpy())
            labels.extend(y.numpy())
    acc = accuracy_score(labels, preds)
    p, r, f, _ = precision_recall_fscore_support(labels, preds, average="binary")
    return acc, p, r, f

print("\nTraining Custom LSTM...")
train_lstm()
lstm_results = eval_model(lstm_model, test_loader_lstm)
print("Custom LSTM Results:", lstm_results)

# PART 2: AWD-LSTM (ULMFiT)

print("\nTraining AWD-LSTM (ULMFiT)...")
path = untar_data(URLs.IMDB)
dls = TextDataLoaders.from_folder(path, train='train', valid='test', bs=64)

awd_learner = text_classifier_learner(dls, AWD_LSTM, metrics=accuracy)
awd_learner.fit_one_cycle(1, 2e-2)
awd_learner.unfreeze()
awd_learner.fit_one_cycle(2, slice(1e-4,1e-3))

preds, labels = awd_learner.get_preds()
pred_labels = preds.argmax(dim=1)
awd_acc = accuracy_score(labels, pred_labels)
awd_prec, awd_rec, awd_f1, _ = precision_recall_fscore_support(labels, pred_labels, average='binary')
print(f"AWD-LSTM Results: Accuracy={awd_acc:.4f}, Precision={awd_prec:.4f}, Recall={awd_rec:.4f}, F1={awd_f1:.4f}")

# PART 3: BERT (BEST MODEL)
print("\nTraining BERT...")

# TOKENIZER & DATASET
bert_tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
MAX_LEN = 256

class BERTDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_len=256):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_len = max_len
    def __len__(self):
        return len(self.labels)
    def __getitem__(self, idx):
        encoding = self.tokenizer(
            self.texts[idx],
            truncation=True,
            padding="max_length",
            max_length=self.max_len,
            return_tensors="pt"
        )
        return {
            "input_ids": encoding["input_ids"].squeeze(0),
            "attention_mask": encoding["attention_mask"].squeeze(0),
            "labels": torch.tensor(self.labels[idx], dtype=torch.long)
        }

train_dataset_bert = BERTDataset(train_texts, train_labels, bert_tokenizer)
test_dataset_bert  = BERTDataset(test_texts, test_labels, bert_tokenizer)

train_loader_bert = DataLoader(train_dataset_bert, batch_size=16, shuffle=True)
test_loader_bert  = DataLoader(test_dataset_bert, batch_size=16)

# MODEL
bert_model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2).to(device)
optimizer_bert = AdamW(bert_model.parameters(), lr=2e-5)

# TRAIN FUNCTION
def train_bert(model, loader, optimizer):
    model.train()
    total_loss = 0
    for batch in loader:
        batch = {k:v.to(device) for k,v in batch.items()}
        outputs = model(**batch)
        loss = outputs.loss
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss/len(loader)

# EVALUATION FUNCTION
def evaluate_bert(model, loader):
    model.eval()
    preds, labels = [], []
    with torch.no_grad():
        for batch in loader:
            labels.extend(batch["labels"].numpy())
            batch = {k:v.to(device) for k,v in batch.items()}
            outputs = model(**batch)
            preds.extend(outputs.logits.argmax(1).cpu().numpy())
    acc = accuracy_score(labels, preds)
    p, r, f, _ = precision_recall_fscore_support(labels, preds, average='binary')
    return acc, p, r, f

# TRAINING LOOP
EPOCHS = 3
for epoch in range(EPOCHS):
    start_time = time.time()
    loss = train_bert(bert_model, train_loader_bert, optimizer_bert)
    end_time = time.time()
    print(f"BERT Epoch {epoch+1}/{EPOCHS} | Loss: {loss:.4f} | Time: {end_time-start_time:.2f}s")

# EVALUATION
start_eval = time.time()
bert_results = evaluate_bert(bert_model, test_loader_bert)
end_eval = time.time()

print("\nBERT Evaluation Results:")
print(f"Accuracy : {bert_results[0]:.4f}")
print(f"Precision: {bert_results[1]:.4f}")
print(f"Recall   : {bert_results[2]:.4f}")
print(f"F1-score : {bert_results[3]:.4f}")
print(f"Evaluation Time: {end_eval-start_eval:.2f}s")

# FINAL COMPARISON TABLE
print("\nFINAL COMPARISON TABLE\n")
print(f"{'Model':<15} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1':<10}")
print(f"{'Custom LSTM':<15} {lstm_results[0]:<10.4f} {lstm_results[1]:<10.4f} {lstm_results[2]:<10.4f} {lstm_results[3]:<10.4f}")
print(f"{'AWD-LSTM':<15} {awd_acc:<10.4f} {awd_prec:<10.4f} {awd_rec:<10.4f} {awd_f1:<10.4f}")
print(f"{'BERT':<15} {bert_results[0]:<10.4f} {bert_results[1]:<10.4f} {bert_results[2]:<10.4f} {bert_results[3]:<10.4f}")
